# Image-to-caption-generator
This project demonstrates an image captioning system that generates descriptive text for images using a combination of vision and language models. Specifically, it leverages a Vision Transformer (ViT) as the encoder and GPT-2 as the decoder to create captions for images. The dataset used for training and evaluation is the COCO2014 dataset.
# Table of contents
Introduction
Model Architecture
Dataset
Training
Evaluation
Results
Installation
Usage
